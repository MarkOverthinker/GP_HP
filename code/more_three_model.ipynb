{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pytomlpp as toml\n",
    "import pandas as pd\n",
    "from data_preprocessing import getXY, data_normalizeation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = toml.load('/home/gyli/GP_HP/cfg/feature_selection.toml')\n",
    "data_path = cfg['data_path']\n",
    "variance_filter_thres = cfg['variance_filter_thres']\n",
    "raw_x, raw_y = getXY(data_path)\n",
    "# raw_x = data_normalizeation(raw_x)\n",
    "future_names = raw_x.columns\n",
    "X, y = raw_x.select(['年龄', '淋巴细胞数', '白蛋白', '活化部分凝血活酶时间', '低密度脂蛋白', '钠', '中性粒细胞数', '甘油三酯', '凝血酶原时间', '红细胞平均体积', '总胆红素']).to_pandas(), np.ravel(raw_y.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K近邻模型交叉验证结果: [0.75005031 0.60487118 0.80595813 0.77355072 0.63486312] 均值 0.7138586936267337 方差 0.07933959601975767\n",
      "随机森林模型交叉验证结果: [0.88206883 0.70229469 0.91626409 0.90257649 0.7071256 ] 均值 0.8220659392581833 方差 0.09644897164433966\n",
      "GBDT模型交叉验证结果: [0.74763534 0.54066023 0.87902576 0.85386473 0.61976651] 均值 0.7281905138752375 方差 0.7281905138752375\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# 创建随机森林模型\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 创建GBDT模型\n",
    "gbdt_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# 创建Pipeline来对数据进行归一化处理\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # 归一化处理\n",
    "    ('model', knn_model)  # 在这里更改模型\n",
    "])\n",
    "\n",
    "# 对K近邻模型进行交叉验证\n",
    "knn_scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "print(\"K近邻模型交叉验证结果:\", knn_scores,'均值',knn_scores.mean(),'方差',knn_scores.std())\n",
    "\n",
    "# 创建随机森林模型\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 创建GBDT模型\n",
    "gbdt_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# 对随机森林模型进行交叉验证\n",
    "rf_scores = cross_val_score(rf_model, X, y, cv=5)\n",
    "print(\"随机森林模型交叉验证结果:\", rf_scores,'均值',rf_scores.mean(),'方差',rf_scores.std())\n",
    "\n",
    "# 对GBDT模型进行交叉验证\n",
    "gbdt_scores = cross_val_score(gbdt_model, X, y, cv=5)\n",
    "print(\"GBDT模型交叉验证结果:\", gbdt_scores,'均值',gbdt_scores.mean(),'方差',gbdt_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_df = pd.DataFrame(columns=['n_neighbors', 'weights', 'p_val', 'cross_val_score', 'mean_score', 'std'])\n",
    "knn_dfs = []\n",
    "n_neighbors = [i for i in range(1, 20)]\n",
    "weights = ['uniform', 'distance']\n",
    "p_vals = [i for i in range(1,10)]\n",
    "for k in n_neighbors:\n",
    "    for w in weights:\n",
    "        for p in p_vals:\n",
    "            knn_model = KNeighborsClassifier(n_neighbors=k, weights=w,p=p)\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),  # 归一化处理\n",
    "                ('model', knn_model)  # 在这里更改模型\n",
    "            ])\n",
    "            # 对K近邻模型进行交叉验证\n",
    "            knn_scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "            row = {'n_neighbors' : k, 'weights' : w, 'p_val' : p, 'mean_score' : knn_scores.mean(), 'std' : knn_scores.std()}\n",
    "            for i, acc in enumerate(knn_scores):\n",
    "                row[f'cross_val_score_{i+1}'] = knn_scores[i]\n",
    "            # knn_df = knn_df.add(row, ignore_index=True)\n",
    "            knn_dfs.append(pd.DataFrame(row, index=[0]))\n",
    "knn_df = pd.concat(knn_dfs)\n",
    "knn_df.to_csv('/home/gyli/GP_HP/result/knn_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "      <th>p_val</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std</th>\n",
       "      <th>cross_val_score_1</th>\n",
       "      <th>cross_val_score_2</th>\n",
       "      <th>cross_val_score_3</th>\n",
       "      <th>cross_val_score_4</th>\n",
       "      <th>cross_val_score_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790223</td>\n",
       "      <td>0.069729</td>\n",
       "      <td>0.849265</td>\n",
       "      <td>0.722826</td>\n",
       "      <td>0.857689</td>\n",
       "      <td>0.831320</td>\n",
       "      <td>0.690016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>0.785674</td>\n",
       "      <td>0.071945</td>\n",
       "      <td>0.846448</td>\n",
       "      <td>0.713969</td>\n",
       "      <td>0.854267</td>\n",
       "      <td>0.829911</td>\n",
       "      <td>0.683776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>3</td>\n",
       "      <td>0.785997</td>\n",
       "      <td>0.070294</td>\n",
       "      <td>0.843429</td>\n",
       "      <td>0.713969</td>\n",
       "      <td>0.856280</td>\n",
       "      <td>0.827899</td>\n",
       "      <td>0.688406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>4</td>\n",
       "      <td>0.785071</td>\n",
       "      <td>0.069902</td>\n",
       "      <td>0.844033</td>\n",
       "      <td>0.714372</td>\n",
       "      <td>0.854469</td>\n",
       "      <td>0.825081</td>\n",
       "      <td>0.687399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>5</td>\n",
       "      <td>0.785232</td>\n",
       "      <td>0.070526</td>\n",
       "      <td>0.844637</td>\n",
       "      <td>0.714372</td>\n",
       "      <td>0.855676</td>\n",
       "      <td>0.825081</td>\n",
       "      <td>0.686393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>distance</td>\n",
       "      <td>5</td>\n",
       "      <td>0.790385</td>\n",
       "      <td>0.096057</td>\n",
       "      <td>0.829744</td>\n",
       "      <td>0.682367</td>\n",
       "      <td>0.908615</td>\n",
       "      <td>0.859702</td>\n",
       "      <td>0.671498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>distance</td>\n",
       "      <td>6</td>\n",
       "      <td>0.788413</td>\n",
       "      <td>0.095221</td>\n",
       "      <td>0.828939</td>\n",
       "      <td>0.682166</td>\n",
       "      <td>0.904589</td>\n",
       "      <td>0.857085</td>\n",
       "      <td>0.669283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>distance</td>\n",
       "      <td>7</td>\n",
       "      <td>0.787688</td>\n",
       "      <td>0.095603</td>\n",
       "      <td>0.826524</td>\n",
       "      <td>0.680757</td>\n",
       "      <td>0.904589</td>\n",
       "      <td>0.857890</td>\n",
       "      <td>0.668680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>distance</td>\n",
       "      <td>8</td>\n",
       "      <td>0.787648</td>\n",
       "      <td>0.094858</td>\n",
       "      <td>0.826927</td>\n",
       "      <td>0.679952</td>\n",
       "      <td>0.904187</td>\n",
       "      <td>0.856079</td>\n",
       "      <td>0.671095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>distance</td>\n",
       "      <td>9</td>\n",
       "      <td>0.787769</td>\n",
       "      <td>0.094704</td>\n",
       "      <td>0.827531</td>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.903784</td>\n",
       "      <td>0.856079</td>\n",
       "      <td>0.671900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors   weights  p_val  mean_score       std  cross_val_score_1  \\\n",
       "0             1   uniform      1    0.790223  0.069729           0.849265   \n",
       "0             1   uniform      2    0.785674  0.071945           0.846448   \n",
       "0             1   uniform      3    0.785997  0.070294           0.843429   \n",
       "0             1   uniform      4    0.785071  0.069902           0.844033   \n",
       "0             1   uniform      5    0.785232  0.070526           0.844637   \n",
       "..          ...       ...    ...         ...       ...                ...   \n",
       "0            19  distance      5    0.790385  0.096057           0.829744   \n",
       "0            19  distance      6    0.788413  0.095221           0.828939   \n",
       "0            19  distance      7    0.787688  0.095603           0.826524   \n",
       "0            19  distance      8    0.787648  0.094858           0.826927   \n",
       "0            19  distance      9    0.787769  0.094704           0.827531   \n",
       "\n",
       "    cross_val_score_2  cross_val_score_3  cross_val_score_4  cross_val_score_5  \n",
       "0            0.722826           0.857689           0.831320           0.690016  \n",
       "0            0.713969           0.854267           0.829911           0.683776  \n",
       "0            0.713969           0.856280           0.827899           0.688406  \n",
       "0            0.714372           0.854469           0.825081           0.687399  \n",
       "0            0.714372           0.855676           0.825081           0.686393  \n",
       "..                ...                ...                ...                ...  \n",
       "0            0.682367           0.908615           0.859702           0.671498  \n",
       "0            0.682166           0.904589           0.857085           0.669283  \n",
       "0            0.680757           0.904589           0.857890           0.668680  \n",
       "0            0.679952           0.904187           0.856079           0.671095  \n",
       "0            0.679549           0.903784           0.856079           0.671900  \n",
       "\n",
       "[342 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/gyli/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/gyli/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/home/gyli/.local/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/home/gyli/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7966/1219272047.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mrf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     \u001b[0mrf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_depth'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_samples_leaf'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_samples_split'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_features'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_score'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mrf_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mrf_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    448\u001b[0m     )\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;31m# For callable scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             )\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/gyli/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/gyli/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/home/gyli/.local/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/home/gyli/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n"
     ]
    }
   ],
   "source": [
    "rf_dfs = []\n",
    "# n_estimators = [i for i in range(100, 300, 100)]\n",
    "# max_depth = [i for i in range(2, 3)]\n",
    "# min_samples_leaf = [2]\n",
    "# min_samples_split = [2]\n",
    "# max_features = [None, 'sqrt', 'log2']\n",
    "n_estimators = [i for i in range(5, 300, 5)]\n",
    "max_depth = [i for i in range(2, 11)]\n",
    "min_samples_leaf = [i for i in range(1, 5)]\n",
    "min_samples_split = [i for i in range(2, 5)]\n",
    "max_features = [None, 'sqrt', 'log2']\n",
    "\n",
    "for n in n_estimators:\n",
    "    for md in max_depth:\n",
    "        for ml in  min_samples_leaf:\n",
    "            for ms in min_samples_split:\n",
    "                for mf in max_features:\n",
    "                    rf_model = RandomForestClassifier(n_estimators=n, max_depth=md, min_samples_leaf=ml, min_samples_split=ms, max_features=mf, random_state=42)\n",
    "                    rf_scores = cross_val_score(rf_model, X, y, cv=5)\n",
    "                    row = {'n_estimators' : n, 'max_depth' : md, 'min_samples_leaf' : ml, 'min_samples_split' : ms, 'max_features' : mf, 'mean_score' : rf_scores.mean(), 'std' : rf_scores.std()}\n",
    "                    for i, acc in enumerate(rf_scores):\n",
    "                        row[f'cross_val_score_{i+1}'] = rf_scores[i]\n",
    "                    rf_dfs.append(pd.DataFrame(row, index=[0]))\n",
    "rf_df = pd.concat(rf_dfs)\n",
    "rf_df.to_csv('/home/gyli/GP_HP/result/rf_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>max_features</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std</th>\n",
       "      <th>cross_val_score_1</th>\n",
       "      <th>cross_val_score_2</th>\n",
       "      <th>cross_val_score_3</th>\n",
       "      <th>cross_val_score_4</th>\n",
       "      <th>cross_val_score_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.698160</td>\n",
       "      <td>0.142422</td>\n",
       "      <td>0.696518</td>\n",
       "      <td>0.486312</td>\n",
       "      <td>0.891103</td>\n",
       "      <td>0.806159</td>\n",
       "      <td>0.610709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.725857</td>\n",
       "      <td>0.126225</td>\n",
       "      <td>0.717046</td>\n",
       "      <td>0.569847</td>\n",
       "      <td>0.898752</td>\n",
       "      <td>0.834340</td>\n",
       "      <td>0.609300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.725857</td>\n",
       "      <td>0.126225</td>\n",
       "      <td>0.717046</td>\n",
       "      <td>0.569847</td>\n",
       "      <td>0.898752</td>\n",
       "      <td>0.834340</td>\n",
       "      <td>0.609300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.698603</td>\n",
       "      <td>0.142235</td>\n",
       "      <td>0.697726</td>\n",
       "      <td>0.487118</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.806159</td>\n",
       "      <td>0.610709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.725937</td>\n",
       "      <td>0.126904</td>\n",
       "      <td>0.716442</td>\n",
       "      <td>0.567834</td>\n",
       "      <td>0.901570</td>\n",
       "      <td>0.832729</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.725937</td>\n",
       "      <td>0.126904</td>\n",
       "      <td>0.716442</td>\n",
       "      <td>0.567834</td>\n",
       "      <td>0.901570</td>\n",
       "      <td>0.832729</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_depth  min_samples_leaf  min_samples_split max_features  \\\n",
       "0           100          2                 2                  2         None   \n",
       "0           100          2                 2                  2         sqrt   \n",
       "0           100          2                 2                  2         log2   \n",
       "0           200          2                 2                  2         None   \n",
       "0           200          2                 2                  2         sqrt   \n",
       "0           200          2                 2                  2         log2   \n",
       "\n",
       "   mean_score       std  cross_val_score_1  cross_val_score_2  \\\n",
       "0    0.698160  0.142422           0.696518           0.486312   \n",
       "0    0.725857  0.126225           0.717046           0.569847   \n",
       "0    0.725857  0.126225           0.717046           0.569847   \n",
       "0    0.698603  0.142235           0.697726           0.487118   \n",
       "0    0.725937  0.126904           0.716442           0.567834   \n",
       "0    0.725937  0.126904           0.716442           0.567834   \n",
       "\n",
       "   cross_val_score_3  cross_val_score_4  cross_val_score_5  \n",
       "0           0.891103           0.806159           0.610709  \n",
       "0           0.898752           0.834340           0.609300  \n",
       "0           0.898752           0.834340           0.609300  \n",
       "0           0.891304           0.806159           0.610709  \n",
       "0           0.901570           0.832729           0.611111  \n",
       "0           0.901570           0.832729           0.611111  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_dfs = []\n",
    "# n_estimators = [i for i in range(100, 300, 100)]\n",
    "# learning_rate = [i * 0.05 for i in range(0, 20, 10)]\n",
    "# subsample = [i*0.05+0.5 for i in range(0, 6, 3)]\n",
    "n_estimators = [i for i in range(5, 300, 5)]\n",
    "learning_rate = [round(i * 0.05, 3) for i in range(1, 20, 1)]\n",
    "subsample = [round(i*0.05+0.4, 3) for i in range(0, 8, 1)]\n",
    "loss = ['log_loss','exponential']\n",
    "for n in n_estimators:\n",
    "    for lr in learning_rate:\n",
    "        for ss in subsample:\n",
    "            for l in loss:\n",
    "                gbdt_model = GradientBoostingClassifier(n_estimators=n, learning_rate=lr, subsample=ss, loss=l, random_state=42)\n",
    "                gbdt_scores = cross_val_score(gbdt_model, X, y, cv=5)\n",
    "                row = {'n_estimators' : n, 'learning_rate' : lr, 'subsample' : ss, 'loss' : l, 'mean_score' : gbdt_scores.mean(), 'std' : gbdt_scores.std()}\n",
    "                for i, acc in enumerate(gbdt_scores):\n",
    "                    row[f'cross_val_score_{i+1}'] = gbdt_scores[i]\n",
    "                gbdt_dfs.append(pd.DataFrame(row, index=[0]))\n",
    "gbdt_df = pd.concat(gbdt_dfs)\n",
    "gbdt_df.to_csv('/home/gyli/GP_HP/result/gbdt_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>subsample</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std</th>\n",
       "      <th>cross_val_score_1</th>\n",
       "      <th>cross_val_score_2</th>\n",
       "      <th>cross_val_score_3</th>\n",
       "      <th>cross_val_score_4</th>\n",
       "      <th>cross_val_score_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.545147</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.545180</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.545147</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.545180</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.545147</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.545180</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.545147</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.545180</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.724889</td>\n",
       "      <td>0.110215</td>\n",
       "      <td>0.748239</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.634058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.724688</td>\n",
       "      <td>0.112590</td>\n",
       "      <td>0.746830</td>\n",
       "      <td>0.559984</td>\n",
       "      <td>0.849034</td>\n",
       "      <td>0.834138</td>\n",
       "      <td>0.633454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.732337</td>\n",
       "      <td>0.111742</td>\n",
       "      <td>0.757094</td>\n",
       "      <td>0.567432</td>\n",
       "      <td>0.858897</td>\n",
       "      <td>0.835346</td>\n",
       "      <td>0.642915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.723320</td>\n",
       "      <td>0.117529</td>\n",
       "      <td>0.743610</td>\n",
       "      <td>0.545290</td>\n",
       "      <td>0.856079</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.638285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.545147</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.545180</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.545147</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.545180</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.545147</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.545180</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.545147</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.545180</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>0.545290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.731249</td>\n",
       "      <td>0.102549</td>\n",
       "      <td>0.764339</td>\n",
       "      <td>0.576490</td>\n",
       "      <td>0.845612</td>\n",
       "      <td>0.819847</td>\n",
       "      <td>0.649960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.729478</td>\n",
       "      <td>0.103779</td>\n",
       "      <td>0.756691</td>\n",
       "      <td>0.580113</td>\n",
       "      <td>0.850040</td>\n",
       "      <td>0.820451</td>\n",
       "      <td>0.640097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.738777</td>\n",
       "      <td>0.107633</td>\n",
       "      <td>0.774603</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.860910</td>\n",
       "      <td>0.832126</td>\n",
       "      <td>0.639895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.732175</td>\n",
       "      <td>0.110021</td>\n",
       "      <td>0.761924</td>\n",
       "      <td>0.566626</td>\n",
       "      <td>0.851651</td>\n",
       "      <td>0.834742</td>\n",
       "      <td>0.645934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  learning_rate  subsample         loss  mean_score       std  \\\n",
       "0           100            0.0       0.50     log_loss    0.545147  0.000080   \n",
       "0           100            0.0       0.50  exponential    0.545147  0.000080   \n",
       "0           100            0.0       0.65     log_loss    0.545147  0.000080   \n",
       "0           100            0.0       0.65  exponential    0.545147  0.000080   \n",
       "0           100            0.5       0.50     log_loss    0.724889  0.110215   \n",
       "0           100            0.5       0.50  exponential    0.724688  0.112590   \n",
       "0           100            0.5       0.65     log_loss    0.732337  0.111742   \n",
       "0           100            0.5       0.65  exponential    0.723320  0.117529   \n",
       "0           200            0.0       0.50     log_loss    0.545147  0.000080   \n",
       "0           200            0.0       0.50  exponential    0.545147  0.000080   \n",
       "0           200            0.0       0.65     log_loss    0.545147  0.000080   \n",
       "0           200            0.0       0.65  exponential    0.545147  0.000080   \n",
       "0           200            0.5       0.50     log_loss    0.731249  0.102549   \n",
       "0           200            0.5       0.50  exponential    0.729478  0.103779   \n",
       "0           200            0.5       0.65     log_loss    0.738777  0.107633   \n",
       "0           200            0.5       0.65  exponential    0.732175  0.110021   \n",
       "\n",
       "   cross_val_score_1  cross_val_score_2  cross_val_score_3  cross_val_score_4  \\\n",
       "0           0.545180           0.545089           0.545089           0.545089   \n",
       "0           0.545180           0.545089           0.545089           0.545089   \n",
       "0           0.545180           0.545089           0.545089           0.545089   \n",
       "0           0.545180           0.545089           0.545089           0.545089   \n",
       "0           0.748239           0.564815           0.853261           0.824074   \n",
       "0           0.746830           0.559984           0.849034           0.834138   \n",
       "0           0.757094           0.567432           0.858897           0.835346   \n",
       "0           0.743610           0.545290           0.856079           0.833333   \n",
       "0           0.545180           0.545089           0.545089           0.545089   \n",
       "0           0.545180           0.545089           0.545089           0.545089   \n",
       "0           0.545180           0.545089           0.545089           0.545089   \n",
       "0           0.545180           0.545089           0.545089           0.545089   \n",
       "0           0.764339           0.576490           0.845612           0.819847   \n",
       "0           0.756691           0.580113           0.850040           0.820451   \n",
       "0           0.774603           0.586353           0.860910           0.832126   \n",
       "0           0.761924           0.566626           0.851651           0.834742   \n",
       "\n",
       "   cross_val_score_5  \n",
       "0           0.545290  \n",
       "0           0.545290  \n",
       "0           0.545290  \n",
       "0           0.545290  \n",
       "0           0.634058  \n",
       "0           0.633454  \n",
       "0           0.642915  \n",
       "0           0.638285  \n",
       "0           0.545290  \n",
       "0           0.545290  \n",
       "0           0.545290  \n",
       "0           0.545290  \n",
       "0           0.649960  \n",
       "0           0.640097  \n",
       "0           0.639895  \n",
       "0           0.645934  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [i for i in range(5, 300, 5)]\n",
    "learning_rate = [round(i * 0.05, 3) for i in range(1, 20, 1)]\n",
    "subsample = [round(i*0.05+0.4, 3) for i in range(0, 8, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
